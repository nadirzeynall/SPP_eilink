{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "annoying-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, classification_report)\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91605436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://16.171.23.137:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "substantial-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://16.171.23.137:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "nervous-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "comprehensive-future",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///C:/Users/eiGroup%20-%20Nadir/Desktop/neptune/mlruns'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "strategic-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/aug_train.csv\")\n",
    "targets = data[[\"target\"]]\n",
    "data.drop([\"enrollee_id\", \"target\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "worse-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "numerical_features = []\n",
    "\n",
    "for column in data.columns:\n",
    "    dtype = str(data[column].dtype)\n",
    "    if dtype in [\"float64\", \"int64\"]:\n",
    "        numerical_features.append(column)\n",
    "    else:\n",
    "        categorical_features.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "computational-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_feature in categorical_features:\n",
    "    data[categorical_feature].fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "atmospheric-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    data[categorical_feature] = le.fit_transform(data[categorical_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "liable-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.values, \n",
    "                                                    targets.values.ravel(), \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=2021,\n",
    "                                                    stratify=targets.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "painful-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13410, 12) (5748, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "collect-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13410,) (5748,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "double-safety",
   "metadata": {},
   "outputs": [
    {
     "ename": "S3UploadFailedError",
     "evalue": "Failed to upload C:\\Users\\EIGROU~1\\AppData\\Local\\Temp\\tmpz4x3f630\\model\\conda.yaml to awsbucketformlflow/b1f546b0690c420b8f3860fbcdcde016/artifacts/model/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\transfer.py:292\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[1;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     future\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    293\u001b[0m \u001b[39m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[39m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[39m# client error.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\s3transfer\\futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[39m# out of this and propagate the exception.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    104\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\s3transfer\\futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\s3transfer\\tasks.py:139\u001b[0m, in \u001b[0;36mTask.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator\u001b[39m.\u001b[39mdone():\n\u001b[1;32m--> 139\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_main(kwargs)\n\u001b[0;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\s3transfer\\tasks.py:162\u001b[0m, in \u001b[0;36mTask._execute_main\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuting task \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with kwargs \u001b[39m\u001b[39m{\u001b[39;00mkwargs_to_display\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m return_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_main(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[39m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m# value to the return value from main().\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\s3transfer\\upload.py:758\u001b[0m, in \u001b[0;36mPutObjectTask._main\u001b[1;34m(self, client, fileobj, bucket, key, extra_args)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[39mwith\u001b[39;00m fileobj \u001b[39mas\u001b[39;00m body:\n\u001b[1;32m--> 758\u001b[0m     client\u001b[39m.\u001b[39mput_object(Bucket\u001b[39m=\u001b[39mbucket, Key\u001b[39m=\u001b[39mkey, Body\u001b[39m=\u001b[39mbody, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_args)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\botocore\\client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\botocore\\client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    979\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mS3UploadFailedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m, f1)\n\u001b[0;32m     23\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m\"\u001b[39m, auc) \n\u001b[1;32m---> 25\u001b[0m mlflow\u001b[39m.\u001b[39;49msklearn\u001b[39m.\u001b[39;49mlog_model(logistic_regression, \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:407\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[39m.\u001b[39mformat(package_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscikit-learn\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_model\u001b[39m(\n\u001b[0;32m    329\u001b[0m     sk_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m     metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    342\u001b[0m ):\n\u001b[0;32m    343\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[39m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39m    containing the following flavors:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    405\u001b[0m \n\u001b[0;32m    406\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[0;32m    408\u001b[0m         artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[0;32m    409\u001b[0m         flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49msklearn,\n\u001b[0;32m    410\u001b[0m         sk_model\u001b[39m=\u001b[39;49msk_model,\n\u001b[0;32m    411\u001b[0m         conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[0;32m    412\u001b[0m         code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[0;32m    413\u001b[0m         serialization_format\u001b[39m=\u001b[39;49mserialization_format,\n\u001b[0;32m    414\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[0;32m    415\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[0;32m    416\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[0;32m    417\u001b[0m         await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[0;32m    418\u001b[0m         pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[0;32m    419\u001b[0m         extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[0;32m    420\u001b[0m         pyfunc_predict_fn\u001b[39m=\u001b[39;49mpyfunc_predict_fn,\n\u001b[0;32m    421\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\models\\model.py:573\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m     _logger\u001b[39m.\u001b[39mwarning(_LOG_MODEL_MISSING_SIGNATURE_WARNING)\n\u001b[0;32m    572\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 573\u001b[0m mlflow\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mfluent\u001b[39m.\u001b[39;49mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39;49martifact_path)\n\u001b[0;32m    574\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_record_logged_model(mlflow_model)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\fluent.py:911\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[1;34m(local_dir, artifact_path)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[39m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    910\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[1;32m--> 911\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\client.py:1137\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[1;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\n\u001b[0;32m   1094\u001b[0m     \u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, local_dir: \u001b[39mstr\u001b[39m, artifact_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39m        is_dir: True\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:465\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[1;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_dir, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    459\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \n\u001b[0;32m    462\u001b[0m \u001b[39m    :param local_dir: Path to the directory of files to write.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_artifact_repo(run_id)\u001b[39m.\u001b[39;49mlog_artifacts(local_dir, artifact_path)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py:170\u001b[0m, in \u001b[0;36mS3ArtifactRepository.log_artifacts\u001b[1;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m    168\u001b[0m     upload_path \u001b[39m=\u001b[39m posixpath\u001b[39m.\u001b[39mjoin(dest_path, rel_path)\n\u001b[0;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m filenames:\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upload_file(\n\u001b[0;32m    171\u001b[0m         s3_client\u001b[39m=\u001b[39;49ms3_client,\n\u001b[0;32m    172\u001b[0m         local_file\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, f),\n\u001b[0;32m    173\u001b[0m         bucket\u001b[39m=\u001b[39;49mbucket,\n\u001b[0;32m    174\u001b[0m         key\u001b[39m=\u001b[39;49mposixpath\u001b[39m.\u001b[39;49mjoin(upload_path, f),\n\u001b[0;32m    175\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py:146\u001b[0m, in \u001b[0;36mS3ArtifactRepository._upload_file\u001b[1;34m(self, s3_client, local_file, bucket, key)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m environ_extra_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     extra_args\u001b[39m.\u001b[39mupdate(environ_extra_args)\n\u001b[1;32m--> 146\u001b[0m s3_client\u001b[39m.\u001b[39;49mupload_file(Filename\u001b[39m=\u001b[39;49mlocal_file, Bucket\u001b[39m=\u001b[39;49mbucket, Key\u001b[39m=\u001b[39;49mkey, ExtraArgs\u001b[39m=\u001b[39;49mextra_args)\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\inject.py:143\u001b[0m, in \u001b[0;36mupload_file\u001b[1;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \n\u001b[0;32m    110\u001b[0m \u001b[39mUsage::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m    transfer.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mwith\u001b[39;00m S3Transfer(\u001b[39mself\u001b[39m, Config) \u001b[39mas\u001b[39;00m transfer:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m transfer\u001b[39m.\u001b[39;49mupload_file(\n\u001b[0;32m    144\u001b[0m         filename\u001b[39m=\u001b[39;49mFilename,\n\u001b[0;32m    145\u001b[0m         bucket\u001b[39m=\u001b[39;49mBucket,\n\u001b[0;32m    146\u001b[0m         key\u001b[39m=\u001b[39;49mKey,\n\u001b[0;32m    147\u001b[0m         extra_args\u001b[39m=\u001b[39;49mExtraArgs,\n\u001b[0;32m    148\u001b[0m         callback\u001b[39m=\u001b[39;49mCallback,\n\u001b[0;32m    149\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eiGroup - Nadir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\transfer.py:298\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[1;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[39m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[39m# client error.\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39mexcept\u001b[39;00m ClientError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mraise\u001b[39;00m S3UploadFailedError(\n\u001b[0;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to upload \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    300\u001b[0m             filename, \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([bucket, key]), e\n\u001b[0;32m    301\u001b[0m         )\n\u001b[0;32m    302\u001b[0m     )\n",
      "\u001b[1;31mS3UploadFailedError\u001b[0m: Failed to upload C:\\Users\\EIGROU~1\\AppData\\Local\\Temp\\tmpz4x3f630\\model\\conda.yaml to awsbucketformlflow/b1f546b0690c420b8f3860fbcdcde016/artifacts/model/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    class_weight = \"balanced\"\n",
    "    max_iter = 1000\n",
    "\n",
    "    logistic_regression = LogisticRegression(class_weight=class_weight, max_iter=max_iter)\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc) \n",
    "    \n",
    "    mlflow.sklearn.log_model(logistic_regression, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84b442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
